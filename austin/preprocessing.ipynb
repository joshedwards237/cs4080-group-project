{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b95b8c32-3023-4e84-8510-b67fa10a6b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import heapq\n",
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import unittest\n",
    "import collections\n",
    "from scipy.spatial import cKDTree\n",
    "import time\n",
    "import psutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72499a14-c374-4ff9-a99d-4eb09cac54c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for sizes of graphs used for runtime/memory usage\n",
    "node_sizes = [25, 50, 75, 100, 125, 150, 175, 200, 225, 250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "138ceb68-72c7-46b5-bc96-5621354f31ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Emily\n",
    "def get_memory_usage():\n",
    "  process = psutil.Process(os.getpid())\n",
    "  # return the bytes\n",
    "  return process.memory_info().rss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4593638c-b27f-4277-9f12-ad1d0bb5888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aux_path_search(G, source, target, removed, via_cost):\n",
    "    heap = [(0, source)]\n",
    "    distances = {source: 0}\n",
    "    \n",
    "    while heap:\n",
    "        cost, node = heapq.heappop(heap)\n",
    "        if cost >= via_cost:  # Stop early if path is already worse\n",
    "            return math.inf\n",
    "        if node == target:\n",
    "            return cost\n",
    "        for neighbor in G.neighbors(node):\n",
    "            if neighbor == removed:\n",
    "                continue\n",
    "            edge_weight = G[node][neighbor].get('weight', 1)\n",
    "            new_cost = cost + edge_weight\n",
    "            if new_cost < distances.get(neighbor, math.inf):\n",
    "                distances[neighbor] = new_cost\n",
    "                heapq.heappush(heap, (new_cost, neighbor))\n",
    "\n",
    "    return math.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd2d05bc-d28c-414e-8f92-28aedba0814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_edge_diff(G, v):\n",
    "    neighbors = list(G.neighbors(v))\n",
    "    shortcuts_added = 0\n",
    "    for u, w in combinations(neighbors, 2):\n",
    "        cost_uv = G[u][v].get('weight') if G.has_edge(u, v) else math.inf\n",
    "        cost_vw = G[v][w].get('weight') if G.has_edge(v, w) else math.inf\n",
    "        if cost_uv == None or cost_vw == None:\n",
    "            continue\n",
    "        via_cost = cost_uv + cost_vw\n",
    "        aux_path_cost = aux_path_search(G, u, w, v, via_cost)\n",
    "        if aux_path_cost > via_cost:\n",
    "            shortcuts_added += 1\n",
    "    edges_removed = len(neighbors)\n",
    "    return shortcuts_added - edges_removed, shortcuts_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f2a628d-e98d-4770-87f5-033887dbd85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contract_node(G_work, v, current_rank, shortcuts, rank_dict, aux_g):\n",
    "    neighbors = list(G_work.neighbors(v))\n",
    "    for u, w in combinations(neighbors, 2):\n",
    "        if not (G_work.has_edge(u, v) and G_work.has_edge(v, w)):\n",
    "            continue\n",
    "\n",
    "        cost_uv = G_work[u][v]['weight']\n",
    "        cost_vw = G_work[v][w]['weight']\n",
    "        via_cost = cost_uv + cost_vw\n",
    "        aux_path_cost = aux_path_search(G_work, u, w, v, via_cost)\n",
    "        if aux_path_cost > via_cost:  # Shortcut is needed\n",
    "            if (u, w) in shortcuts and shortcuts[(u, w)]['weight'] > via_cost:\n",
    "                aux_g[u][w].update({'weight': via_cost, 'via': v})\n",
    "                G_work[u][w].update({'weight': via_cost, 'via': v})\n",
    "                shortcuts[(u, w)]['weight'] = via_cost\n",
    "                shortcuts[(u, w)]['via'].append(v)\n",
    "            else:\n",
    "                shortcuts[(u, w)] = {'weight': via_cost, 'via': [v]}\n",
    "                aux_g.add_edge(u, w, weight=via_cost, shortcut=True, via=v)\n",
    "                G_work.add_edge(u, w, weight=via_cost, shortcut=True, via=v)\n",
    "\n",
    "    rank_dict[v] = current_rank\n",
    "    G_work.remove_node(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44d8cc17-2e02-4d39-88b0-7cdff7370b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_contraction_hierarchy_offline(G):\n",
    "    start_time = time.time()\n",
    "    G_work = G.copy()\n",
    "    G_aux = G.copy()\n",
    "    shortcuts = {}\n",
    "    rank_dict = {}\n",
    "\n",
    "    edge_diffs = {\n",
    "        v: (compute_edge_diff(G, v)[0], G.degree(v))  # (shortcut_count, degree)\n",
    "        for v in G.nodes()\n",
    "    }\n",
    "    order = sorted(edge_diffs, key=lambda v: (edge_diffs[v][0], edge_diffs[v][1]))\n",
    "    current_rank = 0\n",
    "    for v in order:\n",
    "        contract_node(G_work, v, current_rank, shortcuts, rank_dict, G_aux)\n",
    "        current_rank += 1\n",
    "    end_time = time.time()\n",
    "    \n",
    "    return G_aux, rank_dict, order, shortcuts, (end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd4b8d14-17ba-42fc-b832-78e825ae2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_contraction_hierarchy_online(G):\n",
    "    start_time = time.time()\n",
    "    G_work = G.copy()\n",
    "    G_aux = G.copy()\n",
    "    shortcuts = {}\n",
    "    rank_dict = {}\n",
    "    current_rank = 0\n",
    "    process_order = []\n",
    "\n",
    "    edge_diffs = {v: (compute_edge_diff(G_work, v)[0], G_work.degree(v)) for v in G_work.nodes()}\n",
    "\n",
    "    while G_work.nodes():\n",
    "        # Select the node with the smallest edge difference. Tie-break by node degree.\n",
    "        v_min = min(edge_diffs, key=lambda v: (edge_diffs[v][0], edge_diffs[v][1]))\n",
    "\n",
    "        v_neighbors = list(G_work.neighbors(v_min))\n",
    "        edge_diffs.pop(v_min)\n",
    "\n",
    "        process_order.append(v_min)\n",
    "        contract_node(G_work, v_min, current_rank, shortcuts, rank_dict, G_aux)\n",
    "        current_rank += 1\n",
    "\n",
    "        # update edge difference dict\n",
    "        for node in v_neighbors:\n",
    "            if node in edge_diffs:\n",
    "                edge_diffs[node] = compute_edge_diff(G_work, node)[0], G_work.degree(node)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    return G_aux, rank_dict, process_order, shortcuts, (end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c62ccd0-3329-4f9b-8fb7-5a38337df665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bi_dijkstras_ch(aux_g, rank, source, target):\n",
    "    start_time = time.time()\n",
    "    forward_heap = [(0, source)]\n",
    "    reverse_heap = [(0, target)]\n",
    "\n",
    "    forward_dist = {source: 0}\n",
    "    reverse_dist = {target: 0}\n",
    "    processed_forward = set()\n",
    "    processed_reverse = set()\n",
    "\n",
    "    best_path = math.inf\n",
    "    meeting_point = None\n",
    "\n",
    "    while forward_heap or reverse_heap:\n",
    "        # ------ Forward Search ------\n",
    "        if len(forward_heap) != 0:\n",
    "            cost_f, node_f = heapq.heappop(forward_heap)\n",
    "            if node_f in processed_forward:\n",
    "                continue\n",
    "            processed_forward.add(node_f)\n",
    "\n",
    "            for neighbor in aux_g.neighbors(node_f):\n",
    "                if rank[node_f] > rank[neighbor]:\n",
    "                    continue\n",
    "\n",
    "                weight = aux_g[node_f][neighbor]['weight']\n",
    "                new_cost = cost_f + weight\n",
    "\n",
    "                if new_cost < forward_dist.get(neighbor, math.inf):\n",
    "                    forward_dist[neighbor] = new_cost\n",
    "                    heapq.heappush(forward_heap, (new_cost, neighbor))\n",
    "\n",
    "        # ------ Reverse Search ------\n",
    "        if len(reverse_heap) != 0:\n",
    "            cost_r, node_r = heapq.heappop(reverse_heap)\n",
    "            if node_r in processed_reverse:\n",
    "                continue\n",
    "            processed_reverse.add(node_r)\n",
    "\n",
    "            for neighbor in aux_g.neighbors(node_r):\n",
    "                if rank[node_r] > rank[neighbor]:\n",
    "                    continue\n",
    "\n",
    "                weight = aux_g[node_r][neighbor]['weight']\n",
    "                new_cost = cost_r + weight\n",
    "\n",
    "                if new_cost < reverse_dist.get(neighbor, math.inf):\n",
    "                    reverse_dist[neighbor] = new_cost\n",
    "                    heapq.heappush(reverse_heap, (new_cost, neighbor))\n",
    "\n",
    "        # Check for Overlap\n",
    "        common_nodes = processed_forward & processed_reverse\n",
    "        for node in common_nodes:\n",
    "            path_cost = forward_dist[node] + reverse_dist[node]\n",
    "            if path_cost < best_path:\n",
    "                best_path = path_cost\n",
    "                meeting_point = node\n",
    "    end_time = time.time()\n",
    "\n",
    "    return best_path, meeting_point, (end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b7449c5-9111-47d0-8889-d4ffd4e20cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Emily\n",
    "def generate_low_doubling_and_highway_graph(n, dim=2, radius=0.2):\n",
    "    # generate n random points in a dim-dimensional space\n",
    "    points = np.random.rand(n, dim)\n",
    "\n",
    "    # create a k-d tree for efficient nearest neighbor search\n",
    "    tree = cKDTree(points)\n",
    "\n",
    "    # find all pairs within the radius\n",
    "    edges = tree.query_pairs(radius)\n",
    "\n",
    "    # fill the graph\n",
    "    G = nx.Graph()\n",
    "    for i in range(n):\n",
    "        G.add_node(i, pos=points[i])\n",
    "\n",
    "    # Get the position dictionary\n",
    "    pos = nx.get_node_attributes(G, 'pos')  # Get the position dictionary\n",
    "\n",
    "    for u, v in edges:\n",
    "        G.add_edge(u, v)\n",
    "        dist = np.linalg.norm(np.array(pos[u]) - np.array(pos[v]))\n",
    "        G[u][v]['weight'] = dist\n",
    "\n",
    "    return G, points\n",
    "\n",
    "def generate_low_doubling_dimension_graph(n, dim=2, radius=0.2):\n",
    "  G = nx.random_geometric_graph(n, radius)\n",
    "\n",
    "  # Get the position dictionary\n",
    "  pos = nx.get_node_attributes(G, 'pos')\n",
    "\n",
    "  # Add weights based on Euclidean distances\n",
    "  for (u, v) in G.edges():\n",
    "      dist = np.linalg.norm(np.array(pos[u]) - np.array(pos[v]))\n",
    "      G[u][v]['weight'] = dist\n",
    "\n",
    "  return G, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88c481e6-5e75-4967-8abb-71abe81f3385",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCHDijkstra(unittest.TestCase):\n",
    "    max_iters = 1000\n",
    "    tolerance = 1.05 # some small graphs return float path length, if within 5% of cost call them euqal\n",
    "\n",
    "    def test_offline(self):\n",
    "        for _ in range(self.max_iters):\n",
    "            G, _ = generate_low_doubling_dimension_graph(n=20)\n",
    "            no_feasible_path = True\n",
    "            while no_feasible_path:\n",
    "                source = random.choice(list(G.nodes))\n",
    "                target = random.choice(list(G.nodes))\n",
    "                try:\n",
    "                    control_sp = nx.shortest_path_length(G, source=source, target=target, weight='weight')\n",
    "                    no_feasible_path = False\n",
    "                except nx.exception.NetworkXNoPath:\n",
    "                    continue\n",
    "\n",
    "            aux_g_offline, rank_offline, process_order_offline, shortcuts_offline, _ = build_contraction_hierarchy_offline(G)\n",
    "            best_path, _, _ = bi_dijkstras_ch(aux_g_offline, rank_offline, source, target)\n",
    "\n",
    "            lower_bound = control_sp / self.tolerance\n",
    "            upper_bound = control_sp * self.tolerance\n",
    "\n",
    "            self.assertTrue(lower_bound <= best_path <= upper_bound,\n",
    "                            f\"Path cost {best_path} outside range ({lower_bound}, {upper_bound}) for control {control_sp}\")\n",
    "\n",
    "    def test_online(self):\n",
    "        for _ in range(self.max_iters):\n",
    "            G, _ = generate_low_doubling_dimension_graph(n=20)\n",
    "            no_feasible_path = True\n",
    "            while no_feasible_path:\n",
    "                source = random.choice(list(G.nodes))\n",
    "                target = random.choice(list(G.nodes))\n",
    "                try:\n",
    "                    control_sp = nx.shortest_path_length(G, source=source, target=target, weight='weight')\n",
    "                    no_feasible_path = False\n",
    "                except nx.exception.NetworkXNoPath:\n",
    "                    continue\n",
    "                \n",
    "            aux_g_online, rank_online, process_order_online, shortcuts_online, _ = build_contraction_hierarchy_online(G)\n",
    "            best_path, _ , _= bi_dijkstras_ch(aux_g_online, rank_online, source, target)\n",
    "\n",
    "            lower_bound = control_sp / self.tolerance\n",
    "            upper_bound = control_sp * self.tolerance\n",
    "\n",
    "            self.assertTrue(lower_bound <= best_path <= upper_bound,\n",
    "                            f\"Path cost {best_path} outside range ({lower_bound}, {upper_bound}) for control {control_sp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e6a8ed4-efee-466f-8817-d2c9c99de2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".F\n",
      "======================================================================\n",
      "FAIL: test_online (__main__.TestCHDijkstra.test_online)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/34/4kyhs7vx46xffv48sl0nlqjw0000gn/T/ipykernel_47174/2090804154.py\", line 46, in test_online\n",
      "    self.assertTrue(lower_bound <= best_path <= upper_bound,\n",
      "AssertionError: False is not true : Path cost inf outside range (0.7929117759195101, 0.87418523295126) for control 0.8325573647154857\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.545s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=1>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.TextTestRunner().run(unittest.defaultTestLoader.loadTestsFromTestCase(TestCHDijkstra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eaaa0c5-fb26-44e1-b660-48711821de10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Emily\n",
    "def estimate_doubling_constant(G, num_samples=10, r_fraction=0.1):\n",
    "    nodes = list(G.nodes)\n",
    "    shortest_path_lengths = dict(nx.all_pairs_shortest_path_length(G))\n",
    "\n",
    "    # compute approximate max distance in the graph\n",
    "    max_dist = max(max(d.values()) for d in shortest_path_lengths.values())\n",
    "\n",
    "    r = int(r_fraction * max_dist)  # set radius as a fraction of max distance\n",
    "    doubling_constants = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        # pick a random node\n",
    "        center = random.choice(nodes)\n",
    "\n",
    "        # compute number of nodes within distance r and 2r\n",
    "        B_r = {node for node, dist in shortest_path_lengths[center].items() if dist <= r}\n",
    "        B_2r = {node for node, dist in shortest_path_lengths[center].items() if dist <= 2*r}\n",
    "\n",
    "        if len(B_r) > 0:  # avoid division by zero\n",
    "            doubling_constants.append(len(B_2r) / len(B_r))\n",
    "\n",
    "    # compute the estimated doubling constant\n",
    "    estimated_C = max(doubling_constants) if doubling_constants else float('inf')\n",
    "\n",
    "    return estimated_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05ea32d6-7f61-409d-969a-12207eb3e02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Emily\n",
    "def plot_graph(G, points):\n",
    "    pos = {i: points[i] for i in range(len(points))}\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    nx.draw(G, pos, with_labels=False, node_size=50, edge_color=\"gray\")\n",
    "    plt.title(\"Random Geometric Graph with Low Doubling Dimension\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd453a40-08e0-4e4c-b1d8-f0dd862702b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Emily\n",
    "def genGraphSamples(num_nodes, numSamples, lo_hi_lo_doub):\n",
    "  graphs = []\n",
    "  points = []\n",
    "  for _ in range(numSamples):\n",
    "    if not lo_hi_lo_doub:\n",
    "      G, pnts = generate_low_doubling_dimension_graph(num_nodes)\n",
    "      while not nx.is_connected(G) and estimate_doubling_constant(G) > 6:\n",
    "        G, pnts = generate_low_doubling_dimension_graph(num_nodes)\n",
    "      graphs.append(G)\n",
    "      points.append(pnts)\n",
    "    else:\n",
    "      G, pnts = generate_low_doubling_and_highway_graph(num_nodes)\n",
    "      while not nx.is_connected(G) and estimate_doubling_constant(G) > 6:\n",
    "        G, pnts = generate_low_doubling_and_highway_graph(num_nodes)\n",
    "      graphs.append(G)\n",
    "      points.append(pnts)\n",
    "  return graphs, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b7605e5-6c65-48af-9575-48d2595f3bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Emily\n",
    "def samplesPerNodeSizeDict(lo_hi_lo_doub):\n",
    "  size_to_samp = collections.defaultdict(list)\n",
    "  for size in node_sizes:\n",
    "    graphs, points = genGraphSamples(size, 3, lo_hi_lo_doub)\n",
    "    size_to_samp[size] = graphs, points\n",
    "  return size_to_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f185111-2019-4a34-bfc9-31c98b81d966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOW HIGHWAY DIM SET\n",
    "sample_dict_lo_hi_lo_doub = samplesPerNodeSizeDict(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02221b60-29af-4a63-bd15-c188e2c94d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY LOW DOUBLING SET\n",
    "sample_dict_lo_doub = samplesPerNodeSizeDict(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c940b768-b5d7-4eb1-9180-e6a41a320710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Emily\n",
    "def bi_dijkstras(G, s, t):\n",
    "  start_time = time.time()\n",
    "  mem_usage = []\n",
    "  # keep track of the nodes\n",
    "  nodes = G.nodes\n",
    "\n",
    "  # keep track of the distance between node pairs from the forward search\n",
    "  fwd_dist = {node: float('inf') for node in nodes}\n",
    "  fwd_dist[s] = 0\n",
    "\n",
    "  # keep track of the distance between node pairs from the backward search\n",
    "  back_dist = {node: float('inf') for node in nodes}\n",
    "  back_dist[t] = 0\n",
    "\n",
    "  fwdHeap = [(0, s)]\n",
    "  backHeap = [(0, t)]\n",
    "\n",
    "  shortest_path_dist = float('inf')\n",
    "\n",
    "  fwd_seen = set()\n",
    "  back_seen = set()\n",
    "\n",
    "  while fwdHeap and backHeap:\n",
    "    mem_usage.append(get_memory_usage())\n",
    "    fwd_dist_node, node = heapq.heappop(fwdHeap)\n",
    "    if node in fwd_seen:\n",
    "      continue\n",
    "    fwd_seen.add(node)\n",
    "\n",
    "    if fwd_dist_node > shortest_path_dist:\n",
    "      # if we've found the shortest path stop iteration\n",
    "      break\n",
    "\n",
    "    #iterate over neighbors and add them to the heap should there be a shortest path\n",
    "    for nei, data in G[node].items():\n",
    "      weight = data.get('weight', None)\n",
    "      if weight is None:\n",
    "        continue\n",
    "      if fwd_dist[node] + weight < fwd_dist[nei]:\n",
    "        fwd_dist[nei] = fwd_dist[node] + weight\n",
    "        heapq.heappush(fwdHeap, (fwd_dist[nei], nei))\n",
    "\n",
    "    back_dist_node, node = heapq.heappop(backHeap)\n",
    "    if node in back_seen:\n",
    "      continue\n",
    "    back_seen.add(node)\n",
    "    if back_dist_node > shortest_path_dist:\n",
    "      # if we've found the shortest path stop iteration\n",
    "      break\n",
    "\n",
    "    # iterate over the neighbors and add them to the heap should there be a shortest path\n",
    "    for nei, data in G[node].items():\n",
    "      weight = data.get('weight', None)\n",
    "      if weight is None:\n",
    "        continue\n",
    "      if back_dist[node] + weight < back_dist[nei]:\n",
    "        back_dist[nei] = back_dist[node] + weight\n",
    "        heapq.heappush(backHeap, (back_dist[nei], nei))\n",
    "\n",
    "    for node in fwd_seen:\n",
    "      if node in back_seen:\n",
    "        shortest_path_dist = min(shortest_path_dist, fwd_dist[node] + back_dist[node])\n",
    "\n",
    "    end_time = time.time()\n",
    "    after_mem = get_memory_usage()\n",
    "  return shortest_path_dist, (end_time - start_time), np.average(mem_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a355349-d3bf-4e3a-9c9c-83662e7a08b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL TAKES A LONG TIME TO RUN\n",
    "def plotRuntimeAndMemory(low_highway, low_doubling):\n",
    "    # golobal data storage low highway dim\n",
    "    avg_ch_online_time_lh = []\n",
    "    avg_ch_offline_time_lh = []\n",
    "    avg_ch_online_size_lh = []\n",
    "    avg_ch_offline_size_lh = []\n",
    "    avg_offline_bi_di_time_lh = []\n",
    "    avg_online_bi_di_time_lh = []\n",
    "    avg_bi_di_time_lh = []\n",
    "\n",
    "    # golobal data storage low doubling dist\n",
    "    avg_ch_online_time_ld = []\n",
    "    avg_ch_offline_time_ld = []\n",
    "    avg_ch_online_size_ld = []\n",
    "    avg_ch_offline_size_ld = []\n",
    "    avg_offline_bi_di_time_ld = []\n",
    "    avg_online_bi_di_time_ld = []\n",
    "    avg_bi_di_time_ld = []\n",
    "\n",
    "    for size in node_sizes:\n",
    "        print(\"Running with graphs of size: \", size)\n",
    "        if size not in low_highway or size not in low_doubling:\n",
    "            print(f\"Skipping size {size}: No data available.\")\n",
    "            continue\n",
    "\n",
    "        low_h_graphs, _ = low_highway[size]\n",
    "        low_d_graphs, _ = low_doubling[size]\n",
    "\n",
    "        # data storage for all graphs of SIZE, low highway\n",
    "        bi_di_ch_on_times_lh = []\n",
    "        bi_di_ch_off_times_lh = []\n",
    "        bi_di_times_lh = []\n",
    "        online_times_lh = []\n",
    "        online_memory_lh = []\n",
    "        offline_times_lh = []\n",
    "        offline_memory_lh = []\n",
    "\n",
    "        # data storage for all graphs of SIZE, low doubling\n",
    "        bi_di_ch_on_times_ld = []\n",
    "        bi_di_ch_off_times_ld = []\n",
    "        bi_di_times_ld = []\n",
    "        online_times_ld = []\n",
    "        online_memory_ld = []\n",
    "        offline_times_ld = []\n",
    "        offline_memory_ld = []\n",
    "        \n",
    "        for low_h_G, low_d_G in zip(low_h_graphs, low_d_graphs):\n",
    "            no_feasible_path = True\n",
    "            while no_feasible_path:\n",
    "                s_lh = random.choice(list(low_h_G.nodes))\n",
    "                t_lh = random.choice(list(low_h_G.nodes))\n",
    "                try:\n",
    "                    control_sp = nx.shortest_path_length(low_h_G, source=s_lh, target=t_lh, weight='weight')\n",
    "                    no_feasible_path = False\n",
    "                except nx.exception.NetworkXNoPath:\n",
    "                    continue\n",
    "\n",
    "\n",
    "            no_feasible_path = True\n",
    "            while no_feasible_path:\n",
    "                s_ld = random.choice(list(low_d_G.nodes))\n",
    "                t_ld = random.choice(list(low_d_G.nodes))\n",
    "                try:\n",
    "                    control_sp = nx.shortest_path_length(low_d_G, source=s_ld, target=t_ld, weight='weight')\n",
    "                    no_feasible_path = False\n",
    "                except nx.exception.NetworkXNoPath:\n",
    "                    continue\n",
    "\n",
    "            print(\"Processing low highway graph\")\n",
    "            # ------- LOW HIGHWAY ------\n",
    "            # process online and offline CH\n",
    "            aux_g_offline, rank_offline, process_order_offline, shortcuts_offline, ch_off_time = build_contraction_hierarchy_offline(low_h_G)\n",
    "            aux_g_online, rank_online, process_order_online, shortcuts_online, ch_on_time = build_contraction_hierarchy_online(low_h_G)\n",
    "            \n",
    "            # store size of aux-data\n",
    "            offline_memory_lh.append(len(shortcuts_offline))\n",
    "            online_memory_lh.append(len(shortcuts_online))\n",
    "\n",
    "            # store runtime of preprocessing\n",
    "            offline_times_lh.append(ch_off_time)\n",
    "            online_times_lh.append(ch_on_time)\n",
    "\n",
    "            # invoke preprocessing sp \n",
    "            _, _ , offline_time = bi_dijkstras_ch(aux_g_offline, rank_offline, s_lh, t_lh)\n",
    "            _, _ , online_time = bi_dijkstras_ch(aux_g_online, rank_online, s_lh, t_lh)\n",
    "\n",
    "            # store time to find sp using preprocessing\n",
    "            bi_di_ch_off_times_lh.append(offline_time)\n",
    "            bi_di_ch_on_times_lh.append(online_time)\n",
    "\n",
    "            # invoke non-preprocessing sp\n",
    "            _, dij_time, _ = bi_dijkstras(low_h_G, s_lh, t_lh)\n",
    "\n",
    "            # store vanilla bi-di times\n",
    "            bi_di_times_lh.append(dij_time)\n",
    "\n",
    "            print(\"Processing low doubling graph\")\n",
    "            # ------- LOW DOUBLING ------\n",
    "            # process online and offline CH\n",
    "            aux_g_offline, rank_offline, process_order_offline, shortcuts_offline, ch_off_time = build_contraction_hierarchy_offline(low_d_G)\n",
    "            aux_g_online, rank_online, process_order_online, shortcuts_online, ch_on_time = build_contraction_hierarchy_online(low_d_G)\n",
    "            \n",
    "            # store size of aux-data\n",
    "            offline_memory_ld.append(len(shortcuts_offline))\n",
    "            online_memory_ld.append(len(shortcuts_online))\n",
    "\n",
    "            # store runtime of preprocessing\n",
    "            offline_times_ld.append(ch_off_time)\n",
    "            online_times_ld.append(ch_on_time)\n",
    "\n",
    "            # invoke preprocessing sp \n",
    "            _, _ , offline_time = bi_dijkstras_ch(aux_g_offline, rank_offline, s_ld, t_ld)\n",
    "            _, _ , online_time = bi_dijkstras_ch(aux_g_online, rank_online, s_ld, t_ld)\n",
    "\n",
    "            # store time to find sp using preprocessing\n",
    "            bi_di_ch_off_times_ld.append(offline_time)\n",
    "            bi_di_ch_on_times_ld.append(online_time)\n",
    "\n",
    "            # invoke non-preprocessing sp\n",
    "            _, dij_time, _ = bi_dijkstras(low_d_G, s_ld, t_ld)\n",
    "\n",
    "            # store vanilla bi-di times\n",
    "            bi_di_times_ld.append(dij_time)\n",
    "\n",
    "        # ------- LOW HIGHWAY ------\n",
    "        # store the averages\n",
    "        avg_ch_online_time_lh.append(np.mean(online_times_lh))\n",
    "        avg_ch_offline_time_lh.append(np.mean(offline_times_lh))\n",
    "        avg_ch_online_size_lh.append(np.mean(online_memory_lh))\n",
    "        avg_ch_offline_size_lh.append(np.mean(offline_memory_lh))\n",
    "        avg_offline_bi_di_time_lh.append(np.mean(bi_di_ch_off_times_lh))\n",
    "        avg_online_bi_di_time_lh.append(np.mean(bi_di_ch_on_times_lh))\n",
    "        avg_bi_di_time_lh.append(np.mean(bi_di_times_lh))\n",
    "\n",
    "        # ------- LOW DOUBLING ------\n",
    "        # store the averages\n",
    "        avg_ch_online_time_ld.append(np.mean(online_times_ld))\n",
    "        avg_ch_offline_time_ld.append(np.mean(offline_times_ld))\n",
    "        avg_ch_online_size_ld.append(np.mean(online_memory_ld))\n",
    "        avg_ch_offline_size_ld.append(np.mean(offline_memory_ld))\n",
    "        avg_offline_bi_di_time_ld.append(np.mean(bi_di_ch_off_times_ld))\n",
    "        avg_online_bi_di_time_ld.append(np.mean(bi_di_ch_on_times_ld))\n",
    "        avg_bi_di_time_ld.append(np.mean(bi_di_times_ld))\n",
    "        \n",
    "    # Plot 1: Runtime Comparison\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # ------- LOW HIGHWAY ------\n",
    "    plt.plot(node_sizes, avg_bi_di_time_lh, label=\"Vanilla Dijkstra LH\", marker=\"o\")\n",
    "    plt.plot(node_sizes, avg_online_bi_di_time_lh, label=\"Online Dijkstra LH\", marker=\"s\")\n",
    "    plt.plot(node_sizes, avg_offline_bi_di_time_lh, label=\"Offline Dijkstra LH\", marker=\"x\")\n",
    "    # ------- LOW DOUBLING ------\n",
    "    plt.plot(node_sizes, avg_bi_di_time_ld, label=\"Vanilla Dijkstra LD\", marker=\"\")\n",
    "    plt.plot(node_sizes, avg_online_bi_di_time_ld, label=\"Online Dijkstra LD\", marker=\"\")\n",
    "    plt.plot(node_sizes, avg_offline_bi_di_time_ld, label=\"Offline Dijkstra LD\", marker=\"\")\n",
    "    \n",
    "    plt.xlabel(\"Number of Nodes\")\n",
    "    plt.ylabel(\"Average Runtime (seconds)\")\n",
    "    plt.title(\"Vanilla Dijkstra vs Preprocessing Dijkstra Runtime\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(\"pre_vs_vanilla_runtime.png\")\n",
    "    \n",
    "    # Plot 2: Peak Memory Comparison of Preproccesing techniques\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # ------- LOW HIGHWAY ------\n",
    "    plt.plot(node_sizes, avg_ch_offline_size_lh, label=\"Offline-CH LH\", marker=\"o\")\n",
    "    plt.plot(node_sizes, avg_ch_online_size_lh, label=\"Online-CH LH\", marker=\"s\")\n",
    "    # ------- LOW DOUBLING ------\n",
    "    plt.plot(node_sizes, avg_ch_offline_size_ld, label=\"Offline-CH LD\", marker=\"\")\n",
    "    plt.plot(node_sizes, avg_ch_online_size_ld, label=\"Online-CH LD\", marker=\"\")\n",
    "    \n",
    "    plt.xlabel(\"Number of Nodes\")\n",
    "    plt.ylabel(\"Total Shortcuts added\")\n",
    "    plt.title(\"Offline vs Online Size Low Doubling\") \n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(\"on_vs_off_size.png\")\n",
    "\n",
    "    # Plot 3: Runtime of Preprocessing techniques\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # ------- LOW HIGHWAY ------\n",
    "    plt.plot(node_sizes, avg_ch_offline_time_lh, label=\"Offline-CH LH\", marker=\"o\")\n",
    "    plt.plot(node_sizes, avg_ch_online_time_lh, label=\"Online-CH LH\", marker=\"s\")\n",
    "    # ------- LOW DOUBLING ------\n",
    "    plt.plot(node_sizes, avg_ch_offline_time_ld, label=\"Offline-CH LD\", marker=\"\")\n",
    "    plt.plot(node_sizes, avg_ch_online_time_ld, label=\"Online-CH LD\", marker=\"\")\n",
    "\n",
    "    plt.xlabel(\"Number of Nodes\")\n",
    "    plt.ylabel(\"Average Runtime (Seconds)\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(on_vs_off_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc941a4a-abba-4f75-a4a7-43471374e4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with graphs of size:  25\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Running with graphs of size:  50\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Running with graphs of size:  75\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Running with graphs of size:  100\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Running with graphs of size:  125\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Running with graphs of size:  150\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Running with graphs of size:  175\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Running with graphs of size:  200\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Running with graphs of size:  225\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n",
      "Running with graphs of size:  250\n",
      "Processing low highway graph\n",
      "Processing low doubling graph\n"
     ]
    }
   ],
   "source": [
    "plotRuntimeAndMemory(sample_dict_lo_hi_lo_doub, sample_dict_lo_doub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225ab17d-7935-4086-ad6a-a6951af2a3ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2f5206-6603-4982-8c22-b1ec0650433a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
